{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-09-03T15:59:17.721483Z",
     "end_time": "2023-09-03T15:59:17.741310Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import openai\n",
    "import json\n",
    "from Keys import openai_keys\n",
    "import re\n",
    "openai.organization = openai_keys['organization']\n",
    "openai.api_key = openai_keys['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Load the JSON data from the file\n",
    "with open('C:/Users\\Admin\\Favorites\\Links\\Everything\\Stuff\\PostMetacritic\\Source/reddit-oppenheimer-286.json', 'r') as json_file:\n",
    "    comments_by_post = json.load(json_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-03T15:59:17.772321Z",
     "end_time": "2023-09-03T15:59:17.828885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class Post:\n",
    "    def __init__(self, title, ratings, raw):\n",
    "        self.title = title\n",
    "        self.ratings = ratings\n",
    "        self.comments = raw"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-03T01:07:43.645927Z",
     "end_time": "2023-09-03T01:07:43.663792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0stop'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m         breakingBad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     13\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m     rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     rates\u001B[38;5;241m.\u001B[39mappend(rate \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rate \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m breakingBad:\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: '0stop'"
     ]
    }
   ],
   "source": [
    "submissions = list()\n",
    "i = 0\n",
    "total = 8\n",
    "breakingBad = False\n",
    "for title, comments in comments_by_post.items():\n",
    "    if i >= total:\n",
    "        break\n",
    "    coms = list()\n",
    "    rates = list()\n",
    "    for c in comments:\n",
    "        coms.append(c)\n",
    "        inp = input(str(i) + \"/\" + total + \" \" + str(title) + \":\\n\"+ str(c))\n",
    "        if inp.lower() == 'stop':\n",
    "            breakingBad = True\n",
    "            break\n",
    "        rate = int(inp)\n",
    "        rates.append(rate if 0 <= rate <= 2 else 1)\n",
    "    if breakingBad:\n",
    "        break\n",
    "    submissions.append(Post(title, rates, coms))\n",
    "    i += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 3: Serialize the list to JSON\n",
    "json_data = json.dumps([obj.__dict__ for obj in submissions], indent=4)\n",
    "\n",
    "# Save the JSON data to a file\n",
    "with open(\"Datasets/HumanGenerated/dataset\" + str(random.randint(1, 9999)), \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "redditSentiment = list()\n",
    "iter = 0\n",
    "for title, comments in comments_by_post.items():\n",
    "    prompts = [{\"role\": \"system\", \"content\":\n",
    "        'Analyse the sentiment of 16 Reddit comments under a post - \"' + str(title) + '\", use the delimiter \"\\n\\n==COMMENT==\\n\\n\" to distinguish individual comments. Your goal is to write sentiment analysis for each comment towards the topic - \"movie Oppenheimer\", in a format RATING - KEYWORDS. Where RATING is a number from 0 to 10, with 0 representing drastically negative attitude to the topic, 10 for a drastically positive, or 5 for neutral or a comment unrelated to a topic. KEYWORDS are 2-3 words or phrases taken unchanged from a comment, which are most indicative of reasons for such attitude, separate them with a comma (,). Use a semicolon (;) as the delimiter between each comment analysis. Example: \"8 - Exciting visuals, Nolan, direction; 4 - Confusing plot, slow pacing; 5 - long duration, too many characters;\"'}]\n",
    "    delimeter = \"\\n\\n==COMMENT==\\n\\n\"\n",
    "    prompt = delimeter.join(comments)\n",
    "    prompts.append({\"role\": \"user\", \"content\": prompt})\n",
    "    chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-16k\", messages=prompts)\n",
    "    reply = chat.choices[0].message.content\n",
    "    redditSentiment.append(Post(title, reply.split(';'), prompt))\n",
    "    iter += 1\n",
    "    print(str(iter) + \"/\" + str(len(comments_by_post)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
